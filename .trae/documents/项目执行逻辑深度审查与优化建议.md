# 项目逻辑深度审查报告

根据您的要求，我调用了 `best-practice-researcher` 技能，并结合代码库的实际情况，对整个项目的执行逻辑进行了深度审查。

## 1. 执行逻辑现状

*   **混合调度**: `DataProcessor` 成功实现了 `Parallel` (并行) 和 `Serial` (串行) 的分组调度。
*   **上下文管理**:
    *   并行策略使用 `paper_id` 隔离的 `session_path`，确保线程安全。
    *   串行策略 (`stepwise_long`) 使用 `session_path=None`，触发内存复用，实现跨论文记忆。
*   **数据持久化**: 采用“每10条保存一次”的策略，兼顾性能与数据安全。

## 2. 发现的问题 (Critical Issues)

虽然整体架构稳健，但我发现了一个**极其隐蔽但严重**的逻辑缺陷，可能导致 `stepwise_long` 在处理大规模数据时崩溃或行为异常。

### 问题：`ThreadPoolExecutor` 的作用域错误

在 `src/data_processor.py` 的第 156 行：

```python
# 伪代码
for index, row in df.iterrows():
    # ...
    with ThreadPoolExecutor(max_workers=max_workers) as executor:  # <--- 问题在这里
        # 提交并行任务
```

**分析**:
*   您在**每一行循环内部**都创建了一个新的 `ThreadPoolExecutor`。
*   这意味着：处理第 1 篇论文时，创建一个线程池，用完销毁；处理第 2 篇论文时，又创建一遍...
*   **后果**:
    1.  **性能开销**: 频繁创建和销毁线程池非常消耗资源（Context Switching），抵消了并发带来的部分优势。
    2.  **资源泄露风险**: 如果行数非常多（几千行），虽然 Python 的 `with` 会自动清理，但这种模式在高频调用下并不优雅，且无法复用线程资源。
    3.  **并发度受限**: 这种写法实际上是“单篇论文内的策略并发”，而不是“多篇论文的并发”。也就是说，系统永远是**串行处理每一篇论文**，只是在处理单篇论文时，它的几个策略是同时跑的。
    *   *注*: 如果这是您的预期（为了保证输出顺序），那没问题。但如果您的初衷是“同时处理 5 篇论文”，那目前的逻辑是达不到的。

**最佳实践**: 应该在循环**外部**创建一个全局的 `ThreadPoolExecutor`，或者保持现状但明确认知这是“行级并发”。考虑到我们要支持 `stepwise_long` 的串行顺序，**目前的“行级并发”其实是唯一正确的选择**（因为如果多篇论文并行，`stepwise_long` 就无法保证顺序了）。

**结论**: 代码逻辑是为了适配混合模式而做出的妥协，是**正确**的，但性能上不是极致。

## 3. 建议的微调方案

### 3.1 优化 `ThreadPoolExecutor` (可选)
虽然为了保证 `stepwise_long` 的顺序，我们必须按行遍历。但我们可以将 `ThreadPoolExecutor` 移到循环外，以复用线程。

```python
# 优化后
with ThreadPoolExecutor(max_workers=max_workers) as executor:
    for index, row in tqdm(df.iterrows()):
        # ...
        # 使用同一个 executor 提交任务
        futures = {executor.submit(...): name for name in parallel_strategies}
        # 等待结果...
```

这样可以减少线程创建的开销。

### 3.2 增加 API 余额/配额检查 (Resiliency)
目前的重试机制只针对网络错误。如果 API 返回 "Insufficient Balance" (余额不足)，程序会无限重试或报错退出，浪费时间。
**建议**: 在 `llm_client.py` 中增加对特定错误码（如 402 Payment Required）的检测，遇到此类错误直接终止程序并报警。

## 4. 总结
目前的逻辑**没有功能性错误**。它为了兼容长上下文策略的顺序性，牺牲了“多篇论文并行”的能力，选择了“单篇论文内多策略并行”。这是一个合理的设计权衡。

如果您追求极致性能且不介意代码复杂度，可以将 `parallel_strategies` 的处理逻辑完全剥离出来，对所有论文进行大规模并行，最后再与串行的 `stepwise_long` 结果合并。但这会极大地增加代码复杂度（需要维护两个独立的循环和结果对齐逻辑）。

**我的建议**: 保持现状。目前的逻辑清晰、安全、易维护。
