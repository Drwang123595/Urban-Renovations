# 对话持久化存储与管理方案（含上下文超长预警）

为了实现类似 ChatGPT 网页版的对话历史管理与持久化，并增加上下文长度监控与预警机制，我将设计一套基于 JSON 文件的轻量级存储方案。

## 1. 方案核心设计

### 存储结构
*   **目录结构**：
    ```
    Urban Renovation/
    ├── history/
    │   ├── sessions/           # 存放具体对话内容的 JSON 文件
    │   │   ├── session_uuid1.json
    │   │   └── session_uuid2.json
    │   └── index.json          # 索引文件，记录所有会话的摘要信息
    ```

### 关键机制：上下文长度监控（Token 估算）
*   **Token 估算**：由于无法直接从 API 获取精准的 Token 消耗（除非 API 返回 usage），我们将引入简单的字符/单词估算或 tiktoken 库（如果适用）来预估当前 Token 数。
*   **预警阈值**：在 `Config` 中设置 `MAX_CONTEXT_TOKENS`（例如 8k 或 32k，取决于模型）。
*   **兜底反馈**：当历史记录接近阈值时（例如达到 90%），在日志中输出警告，并在 `results` 中标记 `context_warning: True`，提示用户当前上下文可能已被压缩或截断。

## 2. 代码实现模块

### 2.1 增强 `ConversationMemory`
*   **属性**：`session_id`（自动生成 UUID）。
*   **持久化**：
    *   `save()`：保存完整对话到 JSON。
    *   `load(session_id)`：加载历史对话。
*   **监控逻辑**：
    *   `check_token_limit()`：每次 `add_message` 后估算总 Token 数。
    *   若超限，打印醒目警告 `[WARNING] Context length approaching limit!`。

### 2.2 修改 `Config`
*   添加 `HISTORY_DIR`。
*   添加 `MAX_CONTEXT_TOKENS`（DeepSeek 一般为 32k 或更多，暂设保守值）。

### 2.3 命令行管理工具 (`chat_manager.py`)
*   `list`：列出历史会话。
*   `view <session_id>`：查看特定会话内容。
*   `delete <session_id>`：删除。

## 3. 集成到现有流程
*   **自动保存**：在 `Strategy` 执行过程中，实时/定期调用 `memory.save()`。
*   **超长反馈**：如果 `check_token_limit()` 报警，代码将自动在控制台输出提示，建议用户“开启新会话”或“清理历史”。

## 4. 实施步骤
1.  **环境准备**：创建 `history` 目录，更新 `Config`。
2.  **升级 Memory**：实现持久化读写 + Token 估算与报警。
3.  **编写 Manager**：`chat_manager.py`。
4.  **集成测试**：模拟长对话，验证报警机制与文件保存。
