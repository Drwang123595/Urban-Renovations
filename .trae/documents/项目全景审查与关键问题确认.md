# 项目优化详细实施方案

本方案旨在解决当前系统在**长上下文记忆保持**与**高并发处理效率**之间的矛盾，并提供灵活的**结果数据整合**能力。

## 1. 核心重构：混合执行调度器 (Hybrid Scheduler)

### 1.1 背景与问题
*   **现状**: `DataProcessor` 目前将所有策略一视同仁地放入线程池 (`ThreadPoolExecutor`) 并行执行。
*   **冲突**: `stepwise_long` 策略依赖于维护一个全局的 `ConversationMemory` 对象来模拟“跨论文记忆”。在多线程环境下，多个线程同时读写同一个 Memory 对象会导致严重的竞态条件（Race Condition）和上下文乱序（Context Disorder），使得长上下文实验完全失效。
*   **目标**: 让 `stepwise_long` 回归单线程串行执行，同时保持其他无状态策略 (`single`, `cot` 等) 的高并发优势。

### 1.2 技术实现细节 (`src/data_processor.py`)

我们将重写 `run_batch` 方法，引入分组调度逻辑：

#### A. 策略分组
在初始化阶段，根据策略名称自动将任务分为两组：
*   **Serial Group (串行组)**: 包含 `stepwise_long`。
*   **Parallel Group (并行组)**: 包含 `single`, `stepwise`, `cot`, `reflection`。

#### B. 循环内调度流程
对于输入 Excel 中的每一行（每一篇论文）：

1.  **并行任务分发**:
    *   将 **Parallel Group** 中的策略提交给线程池。
    *   **关键参数**: 为每个任务生成独立的 `session_path` (例如 `sessions/task1/paper_001/single.json`)，确保它们互不干扰，线程安全。

2.  **串行任务执行**:
    *   在主线程中，依次调用 **Serial Group** 中的策略。
    *   **关键参数**: `session_path=None`。
    *   **原因**: `stepwise_long` 策略内部会维护 `self.memory`。当 `session_path` 为空时，它会复用内存中的对象，从而实现跨论文的 Context 累积。主线程的阻塞执行保证了论文处理的顺序性（Paper 1 -> Paper 2 -> ...），这是长上下文实验成立的前提。

3.  **结果同步**:
    *   使用 `as_completed` 等待并行任务完成。
    *   将串行结果和并行结果汇总到 `results_lists` 容器中。

4.  **实时保存**:
    *   保持原有的“每 10 条保存一次”机制，确保数据安全。

## 2. 新增工具：结果合并脚本 (`scripts/merge_results.py`)

### 2.1 设计理念
*   **独立性**: 不作为主流程的强制环节，由用户按需调用。
*   **灵活性**: 自动扫描输出目录，无需用户手动指定文件名。

### 2.2 功能规格
*   **输入**: 任务名称（例如 `test1`）。
*   **处理逻辑**:
    1.  定位 `Data/test1/output/` 目录。
    2.  读取该目录下所有 `.xlsx` 文件。
    3.  以原始数据的 `Index` 为基准进行 `Merge`（Join）。
    4.  **列重命名**: 为了区分不同策略，自动给列名加上前缀。
        *   原列名: `是否属于城市更新研究`
        *   新列名: `[Single] Urban Renewal`, `[CoT] Urban Renewal`
*   **输出**: 生成 `Data/test1/Result/merged_comparison_TIMESTAMP.xlsx`。

## 3. 实施步骤

1.  **重构数据处理器**:
    *   修改 `src/data_processor.py`，实现上述“混合调度逻辑”。
2.  **开发合并脚本**:
    *   创建 `scripts/merge_results.py`。
3.  **验证**:
    *   运行一个小批量的测试（如 5 篇论文），同时启用 `single` 和 `stepwise_long`。
    *   验证 `single` 的速度（快）和 `stepwise_long` 的记忆（日志中应显示 Token 累积）。

这个方案在保证科学严谨性（Long Context 有效性）的同时，最大化了系统性能，并提供了便捷的数据分析支持。
