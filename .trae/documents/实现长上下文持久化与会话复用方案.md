# 实现长上下文持久化与会话复用方案（新增策略3）

为了实现跨论文的长对话记忆（即在同一个 Session 中连续处理多篇论文，直到 Token 超限才重置），同时保留原有的“每篇论文独立 Session”的策略以便对比，我将新增一个 **Strategy 3: Stepwise Long Context**。

## 方案设计

### 1. 新增策略类 `StepwiseLongContextStrategy`
*   **位置**：`src/strategies/stepwise_long.py`
*   **逻辑**：
    *   维护一个持久的 `ConversationMemory` 实例。
    *   在处理每篇论文前，调用 `memory.is_context_full()` 检查是否接近 Token 上限。
    *   **未超限**：继续使用当前 Session，追加新论文的 Prompt。
    *   **已超限**：保存并归档当前 Session，创建一个全新的 Session（带 System Prompt），继续处理。
    *   **Prompt 调整**：System Prompt 仅在新 Session 开始时发送一次。

### 2. 增强 `ConversationMemory`
*   **功能**：添加 `is_context_full()` 方法，返回布尔值，用于判断是否达到 `Config.MAX_CONTEXT_TOKENS * threshold`。

### 3. 注册新策略
*   在 `src/strategies/registry.py` 中注册 `stepwise_long`。
*   用户可通过 `--strategy stepwise_long` 调用。

### 4. 保持原有策略不变
*   `SingleTurnStrategy` (Strategy 1)：保持“每篇论文一个独立对话（Session）”。
*   `StepwiseStrategy` (Strategy 2)：保持“每篇论文一个独立对话（Session），但分三步提问”。
*   **对比价值**：
    *   策略2 vs 策略3：可以观察“是否有跨论文的历史记忆”对提取准确率的影响。

## 实施步骤
1.  **修改 Memory**：添加 `is_context_full()` 方法。
2.  **创建 Strategy 3**：编写 `src/strategies/stepwise_long.py`。
3.  **注册策略**：更新 `src/strategies/registry.py` 和 `__init__.py`。
4.  **更新文档**：在实验说明中补充策略3的用法。
